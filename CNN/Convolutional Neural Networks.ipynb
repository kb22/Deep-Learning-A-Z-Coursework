{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import wget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import zipfile\n",
    "import warnings\n",
    "from distutils.dir_util import copy_tree\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('data'):\n",
    "    print(\"Path already exists\")\n",
    "else:\n",
    "    print(\"Creating the data directory\")\n",
    "    os.mkdir('data')\n",
    "    print(\"Directory created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset available\n"
     ]
    }
   ],
   "source": [
    "data_url = 'https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/P16-Convolutional-Neural-Networks.zip'\n",
    "file_name = data_url.split(\"/\")[-1]\n",
    "if not os.path.exists('data/training_set'):\n",
    "    print('Need to download dataset')\n",
    "    wget.download(data_url, out = 'data')\n",
    "    print('Data downloaded')\n",
    "    with zipfile.ZipFile('data/' + file_name, 'r') as file:\n",
    "        print(\"Extracting dataset\")\n",
    "        file.extractall()\n",
    "        copy_tree('Convolutional_Neural_Networks/dataset/', 'data/')\n",
    "        print(\"Dataset extracted and created\")\n",
    "    try:\n",
    "        shutil.rmtree('Convolutional_Neural_Networks')\n",
    "        os.remove('data/' + file_name)\n",
    "        print(\"Extra files removed\")\n",
    "    except:\n",
    "        print(\"Could not delete extra files\")\n",
    "else:\n",
    "    print('Dataset available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/k.bhanot/Personal/Important Work/Deep Learning/Deep-Learning-A-Z-Coursework/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 62, 62)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 31, 31)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3936384   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,937,409\n",
      "Trainable params: 3,937,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), input_shape = (3, 64, 64), activation = 'relu', data_format = 'channels_first'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0/255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('data/training_set', \n",
    "                                                 target_size = (64, 64), \n",
    "                                                 batch_size = 32, \n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('data/test_set', \n",
    "                                            target_size = (64, 64), \n",
    "                                            batch_size = 32, \n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/k.bhanot/Personal/Important Work/Deep Learning/Deep-Learning-A-Z-Coursework/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 261s 1s/step - loss: 0.6503 - acc: 0.6262 - val_loss: 0.5862 - val_acc: 0.6900\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 0.5837 - acc: 0.6935 - val_loss: 0.5805 - val_acc: 0.7090\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 0.5540 - acc: 0.7139 - val_loss: 0.5532 - val_acc: 0.7170\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 0.5367 - acc: 0.7285 - val_loss: 0.5493 - val_acc: 0.7260\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 77s 309ms/step - loss: 0.5108 - acc: 0.7478 - val_loss: 0.5473 - val_acc: 0.7375\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 74s 294ms/step - loss: 0.4984 - acc: 0.7521 - val_loss: 0.6242 - val_acc: 0.6710\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 78s 310ms/step - loss: 0.4830 - acc: 0.7652 - val_loss: 0.5084 - val_acc: 0.7745\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.4673 - acc: 0.7804 - val_loss: 0.5289 - val_acc: 0.7605\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 0.4521 - acc: 0.7817 - val_loss: 0.5669 - val_acc: 0.7450\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.4352 - acc: 0.7949 - val_loss: 0.5290 - val_acc: 0.7640\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 0.4328 - acc: 0.7991 - val_loss: 0.5561 - val_acc: 0.7700\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 0.4111 - acc: 0.8115 - val_loss: 0.5660 - val_acc: 0.7630\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.3961 - acc: 0.8191 - val_loss: 0.5339 - val_acc: 0.7725\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 75s 300ms/step - loss: 0.3781 - acc: 0.8321 - val_loss: 0.6173 - val_acc: 0.7415\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 75s 300ms/step - loss: 0.3673 - acc: 0.8369 - val_loss: 0.5399 - val_acc: 0.7720\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 77s 306ms/step - loss: 0.3545 - acc: 0.8381 - val_loss: 0.5563 - val_acc: 0.7630\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 0.3583 - acc: 0.8376 - val_loss: 0.5454 - val_acc: 0.7785\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.3371 - acc: 0.8539 - val_loss: 0.6342 - val_acc: 0.7450\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.3175 - acc: 0.8606 - val_loss: 0.5723 - val_acc: 0.7670\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 80s 318ms/step - loss: 0.3047 - acc: 0.8655 - val_loss: 0.5917 - val_acc: 0.7640\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.2969 - acc: 0.8730 - val_loss: 0.5668 - val_acc: 0.7755\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 80s 321ms/step - loss: 0.2905 - acc: 0.8788 - val_loss: 0.6368 - val_acc: 0.7610\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 0.2808 - acc: 0.8839 - val_loss: 0.6291 - val_acc: 0.7690\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 77s 308ms/step - loss: 0.2741 - acc: 0.8854 - val_loss: 0.6328 - val_acc: 0.7610\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 0.2415 - acc: 0.9031 - val_loss: 0.6722 - val_acc: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10d977198>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000/32,\n",
    "                         epochs = 25, \n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/32,\n",
    "                         verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model to get test accuracy around 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 62, 62)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 60, 60)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,696,801\n",
      "Trainable params: 3,696,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), input_shape = (3, 64, 64), activation = 'relu', data_format = 'channels_first'))\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 107s 428ms/step - loss: 0.6853 - acc: 0.5824 - val_loss: 0.6372 - val_acc: 0.6585\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 105s 419ms/step - loss: 0.6374 - acc: 0.6395 - val_loss: 0.6059 - val_acc: 0.6900\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 104s 415ms/step - loss: 0.6025 - acc: 0.6804 - val_loss: 0.5736 - val_acc: 0.7120\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 105s 418ms/step - loss: 0.5562 - acc: 0.7181 - val_loss: 0.5478 - val_acc: 0.7140\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 105s 419ms/step - loss: 0.5320 - acc: 0.7375 - val_loss: 0.5331 - val_acc: 0.7425\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 105s 418ms/step - loss: 0.4932 - acc: 0.7609 - val_loss: 0.4884 - val_acc: 0.7725\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 104s 416ms/step - loss: 0.4706 - acc: 0.7746 - val_loss: 0.5072 - val_acc: 0.7565\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 106s 422ms/step - loss: 0.4393 - acc: 0.7890 - val_loss: 0.5152 - val_acc: 0.7645\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.4249 - acc: 0.8041 - val_loss: 0.5459 - val_acc: 0.7555\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 0.3999 - acc: 0.8115 - val_loss: 0.5034 - val_acc: 0.7705\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 0.3877 - acc: 0.8217 - val_loss: 0.5478 - val_acc: 0.7575\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.3621 - acc: 0.8375 - val_loss: 0.5082 - val_acc: 0.7700\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 0.3380 - acc: 0.8500 - val_loss: 0.5655 - val_acc: 0.7705\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 0.3159 - acc: 0.8649 - val_loss: 0.5428 - val_acc: 0.7870\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 0.3019 - acc: 0.8705 - val_loss: 0.5713 - val_acc: 0.7865\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 0.2842 - acc: 0.8776 - val_loss: 0.5761 - val_acc: 0.7860\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 0.2737 - acc: 0.8878 - val_loss: 0.5466 - val_acc: 0.7780\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 100s 398ms/step - loss: 0.2451 - acc: 0.9015 - val_loss: 0.6170 - val_acc: 0.7805\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 1072s 4s/step - loss: 0.2350 - acc: 0.9089 - val_loss: 0.5628 - val_acc: 0.7910\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 2476s 10s/step - loss: 0.2228 - acc: 0.9090 - val_loss: 0.6650 - val_acc: 0.7790\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 106s 425ms/step - loss: 0.2047 - acc: 0.9189 - val_loss: 0.6612 - val_acc: 0.7960\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 110s 440ms/step - loss: 0.1897 - acc: 0.9234 - val_loss: 0.7022 - val_acc: 0.7745\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 105s 420ms/step - loss: 0.1851 - acc: 0.9289 - val_loss: 0.7643 - val_acc: 0.7740\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 108s 430ms/step - loss: 0.1746 - acc: 0.9325 - val_loss: 0.7367 - val_acc: 0.7825\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 108s 430ms/step - loss: 0.1606 - acc: 0.9397 - val_loss: 0.6716 - val_acc: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10c988748>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000/32,\n",
    "                         epochs = 25, \n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/32,\n",
    "                         verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By introducing a new Convolution layer, I was able to have the test accuracy as 79.40%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
